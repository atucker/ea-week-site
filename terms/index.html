<!DOCTYPE html>
<!--[if lt IE 7 ]><html class="ie ie6" lang="en"> <![endif]-->
<!--[if IE 7 ]><html class="ie ie7" lang="en"> <![endif]-->
<!--[if IE 8 ]><html class="ie ie8" lang="en"> <![endif]-->
<!--[if (gte IE 9)|!(IE)]><!--><html lang="en"> <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Terms - Harvard College Effective Altruism</title>
  <meta name="author" content="" />
  <link rel="canonical" href="http://harvardea.org/terms/" />

  <link href="//fonts.googleapis.com/css?family=Open+Sans:200,400,600,800" rel="stylesheet" type="text/css">
  <link rel="shortcut icon" href="/favicon.ico">
  <link rel="alternate" type="application/rss+xml" title="" href="http://harvardea.org/atom.xml" />

  <link rel="stylesheet" href="/assets/css/all.css">
<!--[if IE 7]>
  <link rel="stylesheet" href="/assets/css/font-awesome-ie7.min.css">
<![endif]-->
</head>
<body>
  <div id="fb-root"></div>
  <script>
    window.fbAsyncInit = function() {
    // init the FB JS SDK
    FB.init({
    appId      : '237323783090355',                        // App ID from the app dashboard
    // channelUrl : '//harvardea.org/channel.html', // Channel file for x-domain comms
    status     : true,                                 // Check Facebook Login status
    xfbml      : true                                  // Look for social plugins on the page
    });

    // Additional initialization code such as adding Event Listeners goes here
    };

    // Load the SDK asynchronously
    (function(d, s, id){
    var js, fjs = d.getElementsByTagName(s)[0];
    if (d.getElementById(id)) {return;}
    js = d.createElement(s); js.id = id;
    js.src = "//connect.facebook.net/en_US/all.js";
    fjs.parentNode.insertBefore(js, fjs);
    }(document, 'script', 'facebook-jssdk'));
  </script>
<div class="container">
  <div class="sixteen">
    <h1 class="hea"><a href="/">Harvard College Effective Altruism</a></h1>
    <ul class="topbar">
      <li><a href="/">Home</a></li>
      <li><a href="/events/">Events</a></li>
      <li><a href="/people/">People</a></li>
      <li><a href="/contact/">Contact</a></li>
      <li><a href="/resources/">Resources</a></li>
      <li><a href="/terms/">Terms</a></li>
      <li><a href="/blog/">Blog</a></li>
    </ul>
  </div>
    <hr/>
    <div class="ten columns content">
      <div id="terms">
<h2>Core Ideas</h2>
<p><b><a id='effective altruism'>effective altruism</a></b>: Effective altruism (EA) is the name of a growing social movement and an idea - that of using evidence and reason to find the most effective possible ways of doing good in the world. An effecitve altruist is someone who identifies with and acts according to the concept of effective altruism.</p>

<p><b><a id='cost-effectiveness'>cost-effectiveness</a></b>: The cost-effecitveness of a charitable intervention refers to its marginal impact per dollar. For example, each marginal dollar donated to SCI pays for about 1.8 deworming treatments.</p>

<p><b><a id='impartiality'>impartiality</a></b>: Impartiality is the valuing of all human lives equally, independent of location, age, gender, etc.</p>

<p><b><a id='cause-indifference'>cause-indifference</a></b>: One is cause-indifferent if one differentiates between charities only based on how the charities contribute to good in the world. That is to say, one does not have a "pet cause."</p>

<p><b><a id='prioritization'>prioritization</a></b>: Causes can be categorized according to their scope (how much good or bad they do) and their tractability (how easy they are to improve).</p>

<p><b><a id='counterfactual reasoning'>counterfactual reasoning</a></b>: Counterfactual reasoning is a method of deciding between actions by looking at the expected outcome in each case. For instance, one might consider how some intervention performs compared to a control.</p>

<p><b><a id='leveraging donations'>leveraging donations</a></b>: Sometimes, charitable donations can be leveraged to increase their effect. For example, instead of donating $1000 to charity, one might use the $1000 to hold a fundraiser event which results in the donation of more than $1000.</p>

<h2>Philsophy</h2>
<p><b><a id='consequentialism' href='http://plato.stanford.edu/entries/consequentialism/#ClaUti'>consequentialism</a></b>: Consequentialism is the view that moral claims only depend on consequences or states of the world. That is, a consequentialist believes that the extent to which an act is good or bad depends solely on the extent to which the states of the world it causes are good or bad. Most effective altruists are consequentialists. Moral philosopher and effective altruist Thomas Pogge is one notable exception; he ascribes to a deontological system of ethics (one in which people have duties to do or not do certain actions).</p>

<p><b><a id='utilitarianism' href='http://plato.stanford.edu/entries/consequentialism/#ClaUti'>utilitarianism</a></b>: Utilitiarianism is a particular consequentialist moral theory, which states that an act is good or bad according to the extent to which it increases happiness and decreases suffering. Different variations of utilitarianism define happiness and suffereing in different ways; for instance, preference utilitarianism defines happiness (resp. suffering) as the fulfilment (resp. denial) of one's desires or preferences, whether or not this leads to pleasure. Many EAs ascribe to some form of utilitarianism.</p>

<p><b><a id='population ethics'>population ethics</a></b>: Population ethics asks questions about the relative importance of different sentient beings or groups of sentient beings. Its important questions include: What is the moral status of non-human animals? What is the moral status of not-yet-born humans? Is the total amount of humans with good experiences morally relevant, or does only their average happinness matter? Population ethics is a source of significant disagreement among effective altruists.</p>

<p><b><a id='rationalism' href='http://www.merriam-webster.com/dictionary/rationalism'>rationalism</a></b>: Rationalism is the view that reason and experience / evidence, rather than religious belief and emotional responses, should be the basis of one's actions and opinions.</p>

<p><b><a id='moral realism' href='http://plato.stanford.edu/entries/moral-realism/'>moral realism</a></b>: Moral realism is the claim that morality exists as more than just a human construct, in the same way that most people think of the external world existing independent of humans to perceive it. By contrast, moral non-realism is the claim that morality is just an idea that humans like to talk about.</p>

<h2>Actions and term-requiring causes</h2>
<p><b><a id='earning to give' href='http://80000hours.org/earning-to-give'>earning to give</a></b>: Earning to give refers to the practice of choosing a career not for its direct impact but for its salary, and then donating a significant portion of this salary to effective charities. Earning to give can be more effecitve than direct work because money is flexible, because earning to give is irreplaceable (someone else will sometimes do the direct impact job if you don't), and because it allows individuals to specialize in what they are best at. Many effective altruists earn to give.</p>

<p><b><a id='pledge (GWWC and the other one)' href='http://centreforeffectivealtruism.org/  http://effectivealtruismhub.com/donations'>pledge (GWWC and the other one)</a></b>: Many effecitve altruists sign pledges to donate a significant portion of their incomes to charity. Members of Giving What We Can pledge at least 10% of their income to effective charities to relieve the suffering caused by extreme poverty. TLYCS has a similar pledge. A more general pledge is available at http://effectivealtruismhub.com/donations.</p>

<p><b><a id='x-risk' href='http://www.nickbostrom.com/existential/risks.html'>x-risk</a></b>: An existential risk is a danger that is global in scope and terminal in intensity. That is, it threatens to "either annihilate Earth-originating intelligent life or permanently and drastically curtail its potential." Examples include severe climate change, nuclear warfare, and unfriendly artificifial intelligence.</p>

<p><b><a id='meta-EA'>meta-EA</a></b>: A meta-EA charity is an organization which contributes indirectly by seeking to build the effective altruism movement or increase its efficiency. Examples include GiveWell, CEA, TLYCS, and MIRI.</p>

<h2>Organizations</h2>
<p><b><a id='CEA' href='http://centreforeffectivealtruism.org/'>CEA</a></b>: The Centre for Effective Altruism (CEA) is a coalition of projects related to EA. Giving What We Can and 80,000 Hours are both part of CEA. CEA's other projects include setting priorities between different global challenges and raising public awareness of EA.</p>

<p><b><a id='80K' href='http://80000hours.org/about-us'>80K</a></b>: 80,000 Hours (80K) is an organization that offers free, one-on-one career advice to individuals seeking to use their careers to do the most good in the world. 80K also publishes general research on the social impact of careers to its website.</p>

<p><b><a id='GWWC' href='http://www.givingwhatwecan.org/about-us'>GWWC</a></b>: Giving What We Can (GWWC) is an international society dedicated to eradicating extreme poverty. GWWC recommends cost-effective charities and encourages individuals to sign its pledge, which represents a commitment to donate a fraction of one's incoome to effective anti-poverty charities, GWWC also has local chapters that meet in cities in the UK, USA, and elsewhere.</p>

<p><b><a id='GiveWell' href='http://www.givewell.org/about'>GiveWell</a></b>: GiveWell is a non-profit that evaluates charities in order to find outstanding giving opportunities. In particular, GiveWell seesk out charities who provide strong evidence of impact-per-dollar and room for more funding, and who can demonstrate trustworthiness and transparency. GiveWell recommends just a few charities at a time, and many of these recommendations inform the donations of many effective altruists.</p>

<p><b><a id='TLYCS' href='http://www.thelifeyoucansave.org/aboutus.aspx'>TLYCS</a></b>: The Life You Can Save (TLYCS) is a non-profit founded by philosopher Peter Singer. It promotes effecitve altruism - with a focus on reducing poverty and economic inequality - through public outreach. TLYCS seeks to create local groups of informed givers and a global online community, and encourages individuals to sign its charitable-donation pledge.</p>

<p><b><a id='AMF' href='http://www.againstmalaria.com/Default.aspx http://www.givewell.org/international/top-charities/AMF#Costperlifesaved'>AMF</a></b>: The Against Malaria Foundation (AMF) is a non-profit that funds the distribution of long-lasting insecticidal nets (LLIN) to areas with high incidence of malaria, mostly in Africa. Givewell has recommended AMF as a top charity several times. In 2013, Givewell estimated that it costs AMF about $6.13 to distribute one LLIN and $3,400 to save the life of one child.</p>

<p><b><a id='SCI' href='http://www.givewell.org/international/top-charities/schistosomiasis-control-initiative  http://www3.imperial.ac.uk/schisto/whatwedo'>SCI</a></b>: The Schistosomiasis Control Initiative (SCI) is a non-profit that works with local Ministries of Health across sub-Saharan Africa to treat children and at-risk adults for schistosomiasis and other parasitic worms. GiveWell has recommended SCI as a top charity, and in 2013, estimated that it costs $0.80 to deworm one child, with SCI paying about 70% of these costs (see "leveraging donations").</p>

<p><b><a id='GiveDirectly' href='http://www.givedirectly.org/index.php'>GiveDirectly</a></b>: GiveDirectly is a non-profit that makes direct cash-transfers to poor households in Kenya and Uganda. These cash transfers are unconditonal - recipients may spend them as they see fit. GiveWell has recommended GiveDirectly multiple times.</p>

<p><b><a id='FHI' href='http://www.fhi.ox.ac.uk/research/research-areas/'>FHI</a></b>: The Future of Humanity Institute (FHI) is a research center at Oxford that is leading producer of primary research on existential risk. FHI's main areas of research are global catastrophic risk, applied epistemology, human enhancement, and future technologies.</p>

<p><b><a id='MIRI' href='http://intelligence.org/research/'>MIRI</a></b>: The Machine Intelligence Research Institute (MIRI) is an non-profit whose mission is to "ensure that the creation of smarter-than-human intelligence has a positive impact." MIRI's main activity is to conduct research on a few topics: How can a machine reason coherently about its own behavior? What is a better formalization for decision-making under uncertainty? How can we specify an AI's goals to ensure that it matches our intentions, even as the AI modifies itself? What AI-related interventions are the most beneficial?</p>

</div>
    
      <div class="footer">
        <div class="disclaimer">
  <p>
    Contact us at <a href="mailto:harvardea@gmail.com">harvardea@gmail.com</a>.<br/>
    © Harvard Effective Altruism, 2013 &mdash; built with Jekyll using Lagom theme
  </p>
</div>

      </div>
    </div>
    <div class="five columns sidebar">
      <nav>
  <h2>Latest posts <a class="seeall" href="/events">see all</a></h2>
  <ul class="posts">
    
      <li>
        <a class="post-link" href="/news/2015/01/26/apply/">Apply for the Spring 2015 Philanthropy Fellowship!</a>
        <span class="date">January 26</span>
      </li>
    
      <li>
        <a class="post-link" href="/news/2014/12/04/keith-interview/">How much attention does climate change warrant?</a>
        <span class="date">December 4</span>
      </li>
    
      <li>
        <a class="post-link" href="/news/2014/11/14/eyal-interview/">Discussion of Utility, Fairness, and Risk with Medical Ethicist Nir Eyal</a>
        <span class="date">November 14</span>
      </li>
    
      <li>
        <a class="post-link" href="/news/2014/10/30/hassenfeld-video/">Elie Hassenfeld on GiveWell</a>
        <span class="date">October 30</span>
      </li>
    
      <li>
        <a class="post-link" href="/news/2014/10/30/bostrom-video/">Nick Bostrom on Superintelligence</a>
        <span class="date">October 30</span>
      </li>
    
  </ul>
  <hr/>
  
    <h2>Upcoming events <a class="seeall" href="/events">see all</a></h2>
    <ul class="posts">
      
        <li>
          <span class="speaker">Elie Hassenfeld</span>
          <span class="date">April 6</span> <br/>
          <a class="event-link" href="/event/2015/04/06/hassenfeld/">Elie Hassenfeld on GiveWell&#58; Measuring "Good"</a>
        </li>
      
        <li>
          <span class="speaker">Peter Singer</span>
          <span class="date">April 12</span> <br/>
          <a class="event-link" href="/event/2015/04/12/singer/">The Most Good You Can Do How Effective Altruism is Changing Ideas About Living Ethically</a>
        </li>
      
        <li>
          <span class="speaker">OCS Panel</span>
          <span class="date">April 13</span> <br/>
          <a class="event-link" href="/event/2015/04/13/ocs/">Explore Earning-To-Give: OCS Career Panel</a>
        </li>
      
        <li>
          <span class="speaker">Daron Acemoglu</span>
          <span class="date">April 14</span> <br/>
          <a class="event-link" href="/event/2015/04/14/acemoglu/">States and Rights</a>
        </li>
      
    </ul>
  
  <hr/>
  <h2>Stay in touch</h2>
  <ul class="contact">
    <li>Email us at <a href="mailto:harvardea@gmail.com">harvardea@gmail.com</a>,</li>
    <li>or <a href="https://lists.hcs.harvard.edu/mailman/listinfo/hea-list">sign up for our list</a>.</li>
  </ul>
  <hr/>
  <h2>Organizers <a class="seeall" href="/people">everyone</a></h2>
  <ul class="leadership">
    <li>Ales Flidr '17, co-president </li>
    <li>Angie Jo '16, co-president </li>
    <li>Aaron Tucker '16, co-president </li>
    <li>Nir Eyal, faculty adviser</li>
    <li>John Sturm '15, adviser, co-founder </li>
  </ul>
  <hr/>
  <h2>Further reading</h2>
  <ul class="links">
    <li><a href="http://www.givewell.org/">GiveWell</a></li>
    <li><a href="http://www.givingwhatwecan.org/">Giving What We Can</a></li>
    <li><a href="http://80000hours.org/">80,000 Hours</a></li>
    <li><a href="http://www.thelifeyoucansave.org/">The Life You Can Save</a></li>
  </ul>
  <iframe src="//www.facebook.com/plugins/like.php?href=https%3A%2F%2Fwww.facebook.com%2FHarvardEA&amp;width=220&amp;height=21&amp;colorscheme=light&amp;layout=button_count&amp;action=like&amp;show_faces=true&amp;send=false&amp;appId=237323783090355" scrolling="no" frameborder="0" style="border:none; overflow:hidden; width:220px; height:21px;" allowTransparency="true"></iframe>
</nav>

    </div>
  </div>


<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-44681935-2', 'harvardea.org');
  ga('send', 'pageview');

</script>


</body>
</html>
